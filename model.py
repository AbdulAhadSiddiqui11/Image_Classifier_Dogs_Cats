# -*- coding: utf-8 -*-
"""Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1J2_0g-Fkc6lAOhv7Vzz-lQIzm_ohGbOw
"""

#DataSet : https://www.kaggle.com/thesherpafromalabama/cats-and-dogs-sentdex-tutorial
import numpy as np
import matplotlib.pyplot as plt
import os
import cv2

data_dir = '/content/PetImages' #Path for directory with training data.
categories = ['Dog', 'Cat']
for category in categories:
    path = os.path.join(data_dir, category) #Path for either Cat images or Dog Images
    for img in os.listdir(path):
        img_array = cv2.imread(os.path.join(path,img)) #Converting image to array
        plt.imshow(img_array)
        plt.show()
        break
    break

print('Dimensions : ' + str(img_array.shape) + '\n\n\n' ) #Shape or Dimensions of an image
print(img_array) #Representation of image as array

img_size = 150
new_img_arr = cv2.resize(img_array, (img_size, img_size)) #Resizing image to get a constant shape throughout the dataset.
plt.imshow(new_img_arr)

training_data = []

def create_training_data():
    for category in categories:
        path = os.path.join(data_dir, category) #Path for either Cat images or Dog Images
        class_num = categories.index(category)
        for img in os.listdir(path):
            try:
                img_array = cv2.imread(os.path.join(path,img)) #Converting image to array
                new_img_arr = cv2.resize(img_array, (img_size, img_size)) #Resizing all the images
                training_data.append([new_img_arr, class_num])
            except Exception as e:
                pass

create_training_data()

print(len(training_data)) #Totoal images to train

import random

random.shuffle(training_data) #Shuffling the images

images = []
labels = []

for features,label in training_data:
    images.append(features) #Separating images and labels into two different lists
    labels.append(label)
images = np.array(images).reshape(-1, img_size, img_size, 3)

import pickle

#Saving the processed images and labels list into files
pickle_out = open('cats_dogs_features', 'wb')
pickle.dump(images,pickle_out)
pickle_out.close()
pickle_out = open('cats_dogs_labels', 'wb')
pickle.dump(labels,pickle_out)
pickle_out.close()

#These can be loaded if needed!
#images = pickle.load(open("/content/giiit/cats_dogs_features", 'rb'))
#labels = pickle.load(open("/content/giiit/cats_dogs_labels", 'rb'))

#Building our model
import tensorflow as tf
from tensorflow.keras import models
from tensorflow.keras import layers

model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu',
input_shape=(150, 150, 3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(128, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(128, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Flatten())
model.add(layers.Dropout(0.5))
model.add(layers.Dense(512, activation='relu'))
model.add(layers.Dense(1, activation='sigmoid'))
model.compile(loss = 'binary_crossentropy',
              optimizer = 'adam',
              metrics = ['accuracy'])

#Training our model
history = model.fit(images,labels,batch_size=32, epochs = 20, validation_split = 0.1)

#Saving the trained model!
model.save('Cats_Dogs_classifier.h5')

#plotting accuracy, loss , validation accuracy and validation loss
import matplotlib.pyplot as plt

acc = history.history['acc']
val_acc = history.history['val_acc']
loss = history.history['loss']
val_loss = history.history ['val_loss']

epochs = range(1, len(acc) + 1)

plt.plot(epochs, acc, 'g', label='Training acc')
plt.plot(epochs, val_acc, 'r', label='Validation acc')
plt.title('Training and validation accuracy')
plt.legend()
plt.figure()

plt.plot(epochs, loss, 'b', label='Training loss')
plt.plot(epochs, val_loss, 'r', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()
plt.show()